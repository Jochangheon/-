from huggingface_hub import InferenceClient
import os

def main():
    # Hugging Face í† í° ë¶ˆëŸ¬ì˜¤ê¸°
    hf_token = os.environ.get("HF_TOKEN")
    if not hf_token:
        print("âŒ HF_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ëª¨ë¸ (gpt2) í˜¸ì¶œ
        client = InferenceClient(model="gpt2", token=hf_token)

        prompt = "ì˜¤ëŠ˜ ì €ë… ë©”ë‰´ ì¶”ì²œí•´ì¤˜:"
        print("ğŸ¤– Hugging Face API í˜¸ì¶œ ì¤‘...")
        response = client.text_generation(prompt, max_new_tokens=50)

        print("âœ… ì‘ë‹µ ê²°ê³¼:")
        print(response)

    except Exception as e:
        import traceback
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", repr(e))
        traceback.print_exc()


if __name__ == "__main__":
    main()
