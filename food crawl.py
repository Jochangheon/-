from huggingface_hub import InferenceClient
import os

def main():
    hf_token = os.environ.get("HF_TOKEN")
    if not hf_token:
        print("âŒ HF_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        client = InferenceClient(model="google/flan-t5-base", token=hf_token)

        prompt = "ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ 3ê°€ì§€ë¥¼ ì¶”ì²œí•´ì¤˜."
        print("ğŸ¤– Hugging Face API í˜¸ì¶œ ì¤‘...")
        response = client.text_generation(prompt, max_new_tokens=100)

        print("âœ… ì‘ë‹µ ê²°ê³¼:")
        print(response)

    except Exception as e:
        import traceback
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", repr(e))
        traceback.print_exc()

if __name__ == "__main__":
    main()
